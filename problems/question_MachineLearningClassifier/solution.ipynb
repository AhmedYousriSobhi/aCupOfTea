{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Implement a function, identify_customers, which will build two classifier models based on financial data. The identify_customers functions accepts two arguments:\n",
    "- data_train - a Pandas DataFrame consisting of a binary column 'label' (1 means that the client subscribed to a term deposite, 0 otherwise), three integer columns describing the customer, including their age, account (account balance), and duration (time of being a bank customer) and 17 binary columns (with 'yes' and 'no' values) that also describe the customers.\n",
    "- data_test - a Pandas DataFrame with the same structure as data_train.\n",
    "\n",
    "In the identify_customers function, you should perform the following steps:\n",
    "1. Preprate the 17 binary variables in data_train and data_test by replacing 'yes' with 1, and 'no' with 0. Retaion the rest of the variables without any changes. After this step, you will have two new data frames 'onehot_train' and 'onehot_test'.\n",
    "2. Find the proportion (prep) of clients that have subscribed to a term deposit in onehot_train (use the 'label' variable) and round the value to 3 decimal places. This will be necessary to set weights in the classifier models.\n",
    "3. build a LogisticRegression Classifier on onehot_train. Set the parameters: class_weight={0:prep, 1:1-prep}, random_state=0, max_inter=50.\n",
    "4. Build a RandomForest Classifier on onehot_train. Set the parameters: max_depth=10, random_state=0, n_estimators=30, class_weight={0:prep, 1:1-prep}.\n",
    "5. Do a prediction on onehot_test.\n",
    "\n",
    "After these steps you should return, in identify_customers, a dictionary with the following keys:\n",
    "- onehot_train - data_train DataFrame after replacing 'yes' and 'no' values with 1 and 0 (without 'label' column).\n",
    "- onehot_test - data_test DataFrame after replacing 'yes' and 'no' values with 1 and 0 (without 'label' column).\n",
    "- prep - propotion from point 2, above.\n",
    "- negative_impact - list of column names which reduce the probability of subscribing term deposit (when this variables increases). Use properities of the LogisticRegression classifier to obtain this point.\n",
    "- feature_importance - list of tuples with the five most important varialbes based on feature importances from the RandomForest classifier in the form (column names, feature_importance).\n",
    "- lr_recall - tupple of recall scores from onehot_train and onehot_test after training with the LogisticRegression Classifier.\n",
    "- rf_recall - tupple of recall scores from onehot_train and onehot_test after training with the RandomForest Classifier.\n",
    "- lr_obs - the probabilty of varialbes from LogisticRegression Classifier.\n",
    "- rf_obs - the probabilty of varialbes from RandomForest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.0-cp311-cp311-win_amd64.whl (9.2 MB)\n",
      "     ---------------------------------------- 9.2/9.2 MB 6.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\fawzyjr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.25.1)\n",
      "Collecting scipy>=1.5.0\n",
      "  Downloading scipy-1.11.1-cp311-cp311-win_amd64.whl (44.0 MB)\n",
      "     ---------------------------------------- 44.0/44.0 MB 5.9 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.3.1-py3-none-any.whl (301 kB)\n",
      "     -------------------------------------- 302.0/302.0 kB 3.1 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.1 scikit-learn-1.3.0 scipy-1.11.1 threadpoolctl-3.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('data/data_train.csv')\n",
    "data_test = pd.read_csv('data/data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>account</th>\n",
       "      <th>if_marital</th>\n",
       "      <th>if_default</th>\n",
       "      <th>if_housing</th>\n",
       "      <th>if_loan</th>\n",
       "      <th>if_active_selling</th>\n",
       "      <th>duration</th>\n",
       "      <th>label</th>\n",
       "      <th>occupation_cleaner</th>\n",
       "      <th>...</th>\n",
       "      <th>occupation_own-business</th>\n",
       "      <th>occupation_production</th>\n",
       "      <th>occupation_retired</th>\n",
       "      <th>occupation_services</th>\n",
       "      <th>occupation_student</th>\n",
       "      <th>occupation_technician</th>\n",
       "      <th>occupation_unemployed</th>\n",
       "      <th>education_primary</th>\n",
       "      <th>education_secondary</th>\n",
       "      <th>education_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>2408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>4007</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>482</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>772</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>834</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  account if_marital if_default if_housing if_loan if_active_selling  \\\n",
       "0   41     2408         no         no         no      no                no   \n",
       "1   59     4007        yes         no         no      no                no   \n",
       "2   35      482        yes         no         no      no                no   \n",
       "3   49        0        yes         no        yes      no                no   \n",
       "4   23      834         no         no        yes      no                no   \n",
       "\n",
       "   duration  label occupation_cleaner  ... occupation_own-business  \\\n",
       "0       122      0                 no  ...                      no   \n",
       "1       157      0                 no  ...                      no   \n",
       "2       129      0                 no  ...                      no   \n",
       "3       772      0                 no  ...                      no   \n",
       "4       283      0                 no  ...                      no   \n",
       "\n",
       "  occupation_production occupation_retired occupation_services  \\\n",
       "0                    no                 no                  no   \n",
       "1                    no                yes                  no   \n",
       "2                    no                 no                  no   \n",
       "3                    no                 no                  no   \n",
       "4                    no                 no                  no   \n",
       "\n",
       "  occupation_student occupation_technician occupation_unemployed  \\\n",
       "0                 no                    no                    no   \n",
       "1                 no                    no                    no   \n",
       "2                 no                    no                    no   \n",
       "3                 no                    no                   yes   \n",
       "4                yes                    no                    no   \n",
       "\n",
       "  education_primary education_secondary education_unknown  \n",
       "0                no                  no                no  \n",
       "1               yes                  no                no  \n",
       "2                no                  no                no  \n",
       "3                no                  no                no  \n",
       "4                no                 yes                no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# you can access datasets by calling:\n",
    "# data_train = pd.read_csv(\"data/data_train.csv\")\n",
    "# data_testa = pd.read_csv(\"data/data_test.csv\")\n",
    "\n",
    "def one_hot_encode(data:pd.DataFrame, mapper:dict)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Used to convert categorical binary data to one hot encode values.\n",
    "\n",
    "        PARAMETERS\n",
    "            data: pandas dataframe, input data\n",
    "            mapper: dictionary, to convert from categorical to numerical\n",
    "\n",
    "        RETURN\n",
    "            pandas dataframe with one-hot-encoded\n",
    "    \"\"\"\n",
    "\n",
    "    # create a copy of input data\n",
    "    df = data.copy()\n",
    "\n",
    "    # Select all categorical values\n",
    "    categorical_cols = df.select_dtypes('object').columns.tolist()\n",
    "\n",
    "    # One hot encode categorical values\n",
    "    df[categorical_cols] = df[categorical_cols].replace(mapper)\n",
    "\n",
    "    # return modified dataframe\n",
    "    return df\n",
    "\n",
    "def get_proba(clf, data):\n",
    "    \n",
    "    # Predict probabilities on the test set\n",
    "    probs = clf.predict_proba(data)\n",
    "\n",
    "    # If it's a binary classification problem, use the probabilities for class 1 (positive class)\n",
    "    if len(probs.shape) == 1:\n",
    "        probabilities = probs\n",
    "    else:\n",
    "        probabilities = probs[:, 1]\n",
    "\n",
    "    # Create a DataFrame with the test indices and corresponding probabilities\n",
    "    result_df = pd.DataFrame({'index': data.index, 'probability': probabilities})\n",
    "\n",
    "    # Sort the DataFrame by probabilities in descending order\n",
    "    sorted_indices = result_df.sort_values(by='probability', ascending=False)['index']\n",
    "\n",
    "    return sorted_indices\n",
    "\n",
    "\n",
    "def identify_customers(data_train, data_test):\n",
    "    \n",
    "    # Create a copy of input dataframe\n",
    "    data_train_cp, data_test_cp = data_train.copy(), data_test.copy()\n",
    "\n",
    "    # Step_0:Define varaibles\n",
    "    random_seed = 0\n",
    "    target_col = 'label'\n",
    "\n",
    "    # Step_1: One hot encode dataframes\n",
    "    # Define the mapper for one hot encoder\n",
    "    mapper = {'no':0, 'yes':1}\n",
    "\n",
    "    # One hot encode the dataframes\n",
    "    onehot_train = one_hot_encode(data_train_cp, mapper)\n",
    "    onehot_test = one_hot_encode(data_test_cp, mapper)\n",
    "\n",
    "    # Step_2: Calculate the prop factor\n",
    "    prop = round(onehot_train[onehot_train.label==1].shape[0]/onehot_train.shape[0], 3)\n",
    "\n",
    "    # Define the input, target\n",
    "    x_train, y_train = onehot_train.drop(target_col, axis=1), onehot_train[target_col]\n",
    "    x_test, y_test = onehot_test.drop(target_col, axis=1), onehot_test[target_col]\n",
    "\n",
    "    # Step_3: Logistic Regression\n",
    "    lr = LogisticRegression(\n",
    "        class_weight={\n",
    "            0:prop,\n",
    "            1:1-prop\n",
    "        },\n",
    "        random_state=random_seed,\n",
    "        max_iter=50\n",
    "        )\n",
    "\n",
    "    lr.fit(x_train, y_train)\n",
    "\n",
    "    lr_pred_train = lr.predict(x_train)\n",
    "    lr_pred_test = lr.predict(x_test)\n",
    "\n",
    "    # Step_4: Random Forest Classifier\n",
    "    rf = RandomForestClassifier(\n",
    "        max_depth=10,\n",
    "        random_state=random_seed,\n",
    "        n_estimators=30,\n",
    "        class_weight={\n",
    "            0:prop,\n",
    "            1:1-prop\n",
    "        },\n",
    "    )\n",
    "\n",
    "    rf.fit(x_train, y_train)\n",
    "\n",
    "    rf_pred_train = rf.predict(x_train)\n",
    "    rf_pred_test = rf.predict(x_test)\n",
    "\n",
    "    # calculate negative impact\n",
    "    # Get the coefficients of the features\n",
    "    coefficients = lr.coef_[0]\n",
    "\n",
    "    # Map the coefficients to the column names\n",
    "    feature_coefficients = dict(zip(x_train.columns, coefficients))\n",
    "\n",
    "    # Sort the feature coefficients in ascending order of their absolute values\n",
    "    sorted_features = sorted(feature_coefficients.items(), key=lambda x: abs(x[1]))\n",
    "\n",
    "    # Get the list of column names that reduce the probability of subscribing to a term\n",
    "    n = 3\n",
    "    negative_impact = [feature[0] for feature in sorted_features[:n]]\n",
    "\n",
    "    # Get the feature importances\n",
    "    feature_importances = rf.feature_importances_\n",
    "\n",
    "    # Map the feature importances to the column names\n",
    "    feature_importance_dict = dict(zip(x_train.columns, feature_importances))\n",
    "\n",
    "    # Sort the feature importances in descending order\n",
    "    sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the list of feature names sorted by their importance\n",
    "    feature_importance = [feature[0] for feature in sorted_features[:5]]\n",
    "\n",
    "    # Recall for lr\n",
    "    lr_recall_train = metrics.recall_score(y_train, lr_pred_train)\n",
    "    lr_recall_test = metrics.recall_score(y_test, lr_pred_test)\n",
    "    rf_recall_train = metrics.recall_score(y_train, rf_pred_train)\n",
    "    rf_recall_test = metrics.recall_score(y_test, rf_pred_test)\n",
    "\n",
    "    # calculate proba_index\n",
    "    lr_obs = get_proba(lr, x_test)\n",
    "    rf_obs = get_proba(rf, x_test)\n",
    "            \n",
    "    return {\n",
    "        'onehot_train': onehot_train,\n",
    "        'onehot_test': onehot_test,\n",
    "        'prop': prop,\n",
    "        'negative_impact': negative_impact,\n",
    "        'feature_importance': feature_importance,\n",
    "        'lr_recall': (lr_recall_train, lr_recall_test),\n",
    "        'rf_recall': (rf_recall_train, rf_recall_train),\n",
    "        'lr_obs': lr_obs,\n",
    "        'rf_obs': rf_obs,\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
